# -------------------------------------------------------
# Importing Libraries
# -------------------------------------------------------
import tpqoa
import sqlite3
import pandas as pd
import datetime as dt

from datetime import datetime
from sqlite3 import Error
from tqdm.auto import tqdm

# -------------------------------------------------------

# -------------------------------------------------------
# API Call Class
# -------------------------------------------------------
class APICall:
    def __init__(self):
        """
        Sets the start date, end date and candle frequency to download.
        """
        print('<<<<<< Calling API >>>>>>')
        self.api = tpqoa.tpqoa("oanda.cfg")
        print(self.api.account_type, " | ", self.api.account_id, "\n")
        
        print("#Â Enter Start Date... ex: 2020 1 1 == 1st January 2020")
        self.start_date = datetime(int(input("Year: ")), 
                                   int(input("Month: ")), 
                                   int(input("Day: ")))
        
        print('\n')
        print("### DEVOPS: Press Enter for Current DateTime or Enter Custom End Date.")
        self.end_date = datetime.now()

        print('\n')
        print("# Enter Frequency of Candle... ex: 'M15', 'H2', 'D'")
        self.granularity = input("Candle frequency: ")
        
        # Setting the maximum look-back period based on the frequency
        if self.granularity == 'D':
            max_candle = 5000
        if self.granularity == 'H12':
            max_candle = 2500
        if self.granularity == 'H8':
            max_candle = 1658
        if self.granularity == 'H6':
            max_candle = 1250
        if self.granularity == 'H4':
            max_candle = 832
        if self.granularity == 'H3':
            max_candle = 625
        if self.granularity == 'H2':
            max_candle = 416
        if self.granularity == 'H1':
            max_candle = 208
        if self.granularity == 'M30':
            max_candle = 208
        if self.granularity == 'M15':
            max_candle = 208
        if self.granularity == 'M10':
            max_candle = 208
        if self.granularity == 'M5':
            max_candle = 208
        if self.granularity == 'M1':
            max_candle = 208

        # api maximum period for this frequency:
        delta = dt.timedelta(days=max_candle)

        # Iterating from start date, recording date ranges of days
        self.date_ranges = []
        temp_start_date = self.start_date

        while temp_start_date < self.end_date:
            temp_end_date = temp_start_date + delta

            if temp_end_date > self.end_date:
                temp_end_date = self.end_date

            self.date_ranges.append([temp_start_date, temp_end_date])
            temp_start_date = temp_end_date + dt.timedelta(days=1)
    
    def apicall(self, ticker: str, price: str):
        """
        :param ticker: string of instrument EUR_USD, GBP_JPY
        :param price: string of 'A' = ask price; 'B' = bid price
        :return: pd.DateFrame of OHLCV instrument data.
        """

        s_price = ''
        if price == 'A':
            s_price = '_Ask'
        elif price == 'B':
            s_price = '_Bid'
        print('Downloading ' + ticker + s_price)

        tables = []

        # For each date range, pass dates into API
        for start_dt, end_dt in tqdm(self.date_ranges):
            start = start_dt.strftime("%Y-%m-%dT00:00")
            end = end_dt.strftime("%Y-%m-%dT%H")
            try:
                item = self.api.get_history(instrument=ticker,
                                       start=start,
                                       end=end,
                                       granularity=self.granularity,
                                       price=price)

                tables.append(item)

            except Exception as exception_:
                print("An Error has occurred: ", exception_)
                pass

        single_df = pd.concat(tables)
        # Format and set column index's and name
        single_df.drop('complete', axis=1, inplace=True)
        single_df.reset_index(inplace=True)
        single_df.rename(
            columns={'time': 'DateTime', 'o': ticker + '_' + 'Open', 'h': ticker + '_' + 'High', 'l': ticker + '_' + 'Low',
                     'c': ticker + '_' + 'Close', 'volume': ticker + '_' + 'Volume'}, inplace=True)
        single_df.set_index(['DateTime'], inplace=True)

        # Puts instrument name as table header (USEFUL FEATURE)
        # single_df.columns = pd.MultiIndex.from_product([[ticker], single_df.columns])

        return single_df
        
    def market_cap(self):
        """
        Downloads all OANDA instruments and places into a bid and ask dataframe.  
        """
        print('Searching from: ', self.start_date, ' | ', self.end_date, ' at a frequency of:', self.granularity)
        print('<<<<<< Downloading Instrument Database >>>>>>')
        inst = pd.DataFrame(self.api.get_instruments()).pop(1)
        ask = []
        bid = []
        for i in range(len(inst)):
            askdf = self.apicall(inst[i], "A")
            ask.append(askdf)
            biddf = self.apicall(inst[i], "B")
            bid.append(biddf)

        ask = pd.concat(ask, axis=1)
        bid = pd.concat(bid, axis=1)
        print('<<<<<< Download Complete >>>>>>')

        return ask, bid
        
        
        
# -------------------------------------------------------
# SQL Functions
# -------------------------------------------------------
def sql_make_db(db_name: str, table_name: str, df: pd.DataFrame):
    """
    :param table_name:
    :param db_name:
    :param df: pd.DataFrame
    :return: SQL database saved to directory
    """
    con = None
    try:
        con = sqlite3.connect(db_name)
        print("Connection established: " + db_name)

    except Error:
        print(Error)

    df.to_sql(name=table_name, con=con, if_exists='replace')
    con.commit()
    con.close()
    print("Connection closed: " + db_name)
    
def sql_access_table(instrument_table, db_name: str):
    """
    :param db_name: SQL database saved locally
    :param instrument_table: a List of instruments to pull from db
    :return: pd.DataFrame of OHLCV data
    """
    con = None
    try:
        con = sqlite3.connect(db_name)
        print("Connection established: " + db_name)

    except Error as problem:
        print("An Error occured: ", Error)

    df = pd.read_sql("SELECT * FROM " + str(instrument_table), con)
    con.close()
    print("Connection Closed: " + db_name)
    return df
# -------------------------------------------------------


if __name__ == '__main__':
    model_start = APICall()
    ask_df, bid_df = model_start.market_cap()
    sql_make_db('ask', 'all_instruments_ask', ask_df)
    sql_make_db('bid', 'all_instruments_bid', bid_df)
